---
title: TypeScript SDK Fine-tuning
subtitle: How to create a fine-tuned LoRA using OctoAI's TypeScript SDK
slug: media-gen-solution/fine-tuning-stable-diffusion/typescript-sdk-finetuning
---

This guide will walk you through creating a fine-tuned LoRA using our TypeScript SDK to upload image file assets, creating a tune, and then using that LoRA to run an inference using our Image Gen service once it's ready.

Please see [Fine-tuning Stable Diffusion](/docs/api-reference/fine-tuning/create) for more specifics about each parameter in the fine-tuning API, using curl, or the Python SDK. Our [Asset Library API reference](/docs/api-reference/asset-library/list) documentation goes more into the specifics of using different asset methods as well.

#### Requirements

- Please [create an OctoAI API token](/docs/getting-started/how-to-create-an-octoai-access-token) if you don't have one already.
- Please also verify you've completed [TypeScript SDK Installation & Setup](/docs/typescript-sdk/installation-and-setup).
- If you use the `OCTOAI_TOKEN` environment variable for your token, you can instantiate the client with `const octoai = new OctoAIClient()` or pass the token as a parameter to the constructor like `const octoai = new OctoAIClient({ apiKey: process.env.OCTOAI_TOKEN })`.
- An account and API token is required for all the following steps.

#### High-level steps to creating a fine-tuned LoRA

In order to run a LoRA fine-tuning job, you need to complete a few steps:

1. Create image file assets using the Asset Library, then wait for those assets' status to be `ready`
2. Either create a checkpoint asset you would like to use or get one from OctoAI's public checkpoints.
3. Create a tune job, then wait for the status to be `succeeded`.
4. Run an inference with the new LoRA.

Directions with all the code put together are included at the bottom of the document, but at each step we will cover additional information.

#### 1) Creating image file assets

[Asset Library in the TypeScript SDK](/docs/api-reference/asset-library/list) covers more specifics about the methods, so this example will be focused on a code snippet for uploading multiple files from a folder at once.

In this example, we will use multiple photos of a toy poodle named Mitchi.

```TypeScript TypeScript
import fs from "node:fs";
import { OctoAIClient } from "@octoai/sdk";

const octoai = new OctoAIClient({
  apiKey: process.env.OCTOAI_TOKEN,
});

const fileNames = fs.readdirSync("./images");

console.log("Uploading files...");

const assets = await Promise.all(
    fileNames.map((fileName) => {
        const imageName = fileName.split(".")[0];

        return octoai.assetLibrary.upload(`./images/${fileName}`, {
            name: imageName,
            description: imageName,
            assetType: "file",
            data: {
                assetType: "file",
                fileFormat: "jpg",
            },
        });
    })
);

console.log("Waiting for assets to be ready...");

for (const { asset } of assets) {
    await octoai.assetLibrary.waitForReady(asset.id);
    console.log(`Asset "${asset.name}" is ready`);
}
```

After this completes, all assets will hopefully be in the ready state, or you should time out. Mitchi is now on OctoAI!

![astropus.png](https://www.datocms-assets.com/45680/1703625201-image-of-mitchi.jpeg?max-w=2000&auto=compress)

#### 2) Get a checkpoint asset to use for tuning our LoRA

Next, you'll need a checkpoint to use to tune your asset. In this example, we will just use the default checkpoint using Stable Diffusion 1.5, but you can also use other public OctoAI checkpoints or create your own using the Asset Library.

```TypeScript TypeScript
const checkpoint = await octoai.assetLibrary.get("octoai:default-sd15");
```

#### 3) Creating a tune

We can create a tune by passing in the id of the checkpoint we'd like to use and the ids of the file assets that we created in Step 1. If you want more accurate results, you can add captions to each image to give more thorough descriptions. If no custom captions are provided, the trigger word will be used as a default.

```TypeScript TypeScript
console.log("Creating tune...");

let tune = await octoai.fineTuning.create({
    name: "mitchi",
    description: "mitchi",
    details: {
        tuneType: "lora_tune",
        baseCheckpoint: {
            checkpointId: checkpoint.asset.id,
        },
        // You can add a `caption` to each file for more accurate results
        files: assets.map(({ asset }) => ({ fileId: asset.id })),
        steps: 10,
        triggerWords: ["sksmitchi"],
    },
});

console.log("Waiting for tune to be ready...");

while (tune.status !== "failed" && tune.status !== "succeeded") {
    await new Promise((resolve) => setTimeout(resolve, 1000));
    tune = await octoai.fineTuning.get(tune.id);
}
```

#### 4) Run an inference with the tuned LoRA

Next, you can run an inference with the tuned LoRA

```TypeScript TypeScript
console.log("Generating image...");

const { images } = await octoai.imageGen.generateSdxl({
    prompt: "A photo of an sksmitchi as a puppy",
    negativePrompt: "Blurry photo, distortion, low-res, poor quality, extra limbs, extra tails",
    loras: {
        mitchi: 0.8,
    },
    numImages: 1,
});

images.forEach((image, index) => {
    if (image.imageB64) {
        const buffer = Buffer.from(image.imageB64, "base64");
        fs.writeFileSync(`result${index}.jpg`, buffer);
    }
});
```

The end result will be a saved poodle to your local folder.

![Stable Diffusion Tuned LoRA generated toy poodle puppy](https://www.datocms-assets.com/45680/1706909402-12c9837-cute_finetuning_poodle.jpeg?max-w=2000&auto=compress)

result0.jpg

#### Putting it all together: From Asset Creation to Running an Inference with Tuned LoRA

```TypeScript TypeScript
import { writeFileSync } from "node:fs";
import { OctoAIClient } from "@octoai/sdk";

const octoai = new OctoAIClient({
    apiKey: process.env.OCTOAI_TOKEN,
});

const fileNames = fs.readdirSync("./images");

console.log("Uploading files...");

const assets = await Promise.all(
    fileNames.map((fileName) => {
        const imageName = fileName.split(".")[0];

        return octoai.assetLibrary.upload(`./images/${fileName}`, {
            name: imageName,
            description: imageName,
            assetType: "file",
            data: {
                assetType: "file",
                fileFormat: "jpg",
            },
        });
    })
);

console.log("Waiting for assets to be ready...");

for (const { asset } of assets) {
    await octoai.assetLibrary.waitForReady(asset.id);
    console.log(`Asset "${asset.name}" is ready`);
}

const checkpoint = await octoai.assetLibrary.get("octoai:default-sd15");

console.log("Creating tune...");

let tune = await octoai.fineTuning.create({
    name: "mitchi",
    description: "mitchi",
    details: {
        tuneType: "lora_tune",
        baseCheckpoint: {
            checkpointId: checkpoint.asset.id,
        },
        files: assets.map(({ asset }) => ({ fileId: asset.id })),
        steps: 10,
        triggerWords: ["sksmitchi"],
    },
});

console.log("Waiting for tune to be ready...");

while (tune.status !== "failed" && tune.status !== "succeeded") {
    await new Promise((resolve) => setTimeout(resolve, 1000));
    tune = await octoai.fineTuning.get(tune.id);
}

console.log("Generating image...");

const { images } = await octoai.imageGen.generateSdxl({
    prompt: "A photo of an sksmitchi as a puppy",
    negativePrompt: "Blurry photo, distortion, low-res, poor quality, extra limbs, extra tails",
    loras: {
        mitchi: 0.8,
    },
    numImages: 1,
});

images.forEach((image, index) => {
    if (image.imageB64) {
        const buffer = Buffer.from(image.imageB64, "base64");
        fs.writeFileSync(`result${index}.jpg`, buffer);
    }
});
```
