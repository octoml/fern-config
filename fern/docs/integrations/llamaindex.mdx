---
title: LlamaIndex Integration
subtitle: >-
  A developer building AI apps can now access highly optimized LLMs and
  Embeddings models on OctoAI.
slug: integrations/llamaindex
---

## Introduction
LlamaIndex strives to help manage the interactions between your language modles and private DataTransfer. 
If you are building your application and using LlamaIndex you benefit from the vast ecosystem of integrations, and top LLMs amd Embeddings models hosted by OctoAI.


## OctoAI's LLMs and Embeddings classes in LlamaIndex
Get started reviewing more about [LlamaIndex](https://docs.llamaindex.ai/en/stable/), and [signing up for a free OctoAI account](https://identity.octo.ai/oauth/account/sign-up?redirectUrl=https%3A%2F%2Foctoai.cloud%2Foauth%2Fcallback). 

LlamaIndex has both Python and TypScript libraries. OctoAI is available in the Python SDK. 

### Using the LlamaIndex integration class for OctoAI LLMs
To use OctoAI LLM endpoints with LlamaIndex start with the code below using Llama 3 8B as the LLM.  

```python 
from os import environ
from llama_index.llms.octoai import OctoAI

OCTOAI_API_KEY = environ.get("OCTOAI_TOKEN")

octoai = OctoAI(model="meta-llama-3-8b-instruct", token=OCTOAI_API_KEY)

# Using complete
response = octoai.complete("Octopi can not play chess because...")
print(response)

print("\n=====================\n")

# Using the chat interface
from llama_index.core.llms import ChatMessage

messages = [
    ChatMessage(
        role="system",
        content="Below is an instruction that describes a task. Write a response that appropriately completes the request.",
    ),
    ChatMessage(role="user", content="Write a short blog about Seattle"),
]
response = octoai.chat(messages)
print(response)
```

### Using the LlamaIndex integration class for OctoAI Embeddings
To use OctoAI Embedding endpoints with llamaindex 
you can use the code below to get started. Weâ€™re using GTE large in the example below (default model).

```python 
from os import environ
from llama_index.embeddings.octoai import OctoAIEmbedding

OCTOAI_API_KEY = environ.get("OCTOAI_TOKEN")
embed_model = OctoAIEmbedding(api_key=OCTOAI_API_KEY)

# Single embedding request
embeddings = embed_model.get_text_embedding("Once upon a time in Seattle.")
assert len(embeddings) == 1024
print(embeddings[:10])


# Batch embedding request
texts = [
    "Once upon a time in Seattle.", 
    "This is a test.", 
    "Hello, world!"
]
embeddings = embed_model.get_text_embedding_batch(texts)
assert len(embeddings) == 3
print(embeddings[0][:10])
```

## Building LlamaIndex Agents with OctoAI endpoints
There are different types of agent classes in LlamaIndex. Each one of these classes implement different types of agentic programming patterns. In the following section we will take a look at how to build two types of agents with OctoAI endpoints:
- ReAct Agents
- OpenAI Agents

### LlamaIndex ReAct Agents with OctoAI
ReAct agents are based in an execution cycle comprised of three steps: Reason, Obersve, Act. This is outlined by the [ReAct research paper](https://react-lm.github.io/). One can build ReAct agents in LlamaIndex by using the `OpenAILike` and `ReActAgent` classes like so:
```python
from llama_index.core.agent import ReActAgent
from llama_index.llms.openai_like import OpenAILike

# Create an llm object to use for the ReActAgent
llm = OpenAILike(
    model="meta-llama-3.1-70b-instruct",
    api_base="https://text.octoai.run/v1",
    api_key=environ["OCTOAI_API_KEY"],
    context_window=40000,
    is_function_calling_model=True,
    is_chat_model=True,
)

# Here we define a list of tools available to the ReAct agent
tools = [...]

agent = ReActAgent.from_tools(
    tools,
    llm=llm,
    verbose=True,
    max_turns=10,
)
```
[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/ytang07/ai_agents_cookbooks/)
[![Open in Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/ytang07/ai_agents_cookbooks/)

ReAct agents are very convenient and popular to create. One consideration to have is that this class in particular does not use the tool's API for the LLM requests, so prompting may need to be adjusted in order to meet your performance requirements. You can see a fully working example of this pattern in [this Jupyter Notebook](https://github.com/ytang07/ai_agents_cookbooks/blob/main/llamaindex/llama31_8b_rag_agent.ipynb) written by [Yujian Tang](https://github.com/ytang07).

### LlamaIndex OpenAI Agents with OctoAI
OpenAI agents are a good class to use to develop agents based on OSS models. In particular, this class makes use of the tools API of our LLM endpoints, which will provide better behavior than a prompt-only approach. One can build OpenAI agents in LlamaIndex by using the `OpenAILike` and `OpenAIAgent` classes like so:
```python
from llama_index.agent.openai import OpenAIAgent
from llama_index.llms.openai_like import OpenAILike

llm = OpenAILike(
    model="meta-llama-3.1-70b-instruct",
    api_base="https://text.octoai.run/v1",
    api_key=environ["OCTOAI_API_KEY"],
    context_window=10000,
    is_function_calling_model=True,
    is_chat_model=True,
)

# we have pre-defined a set of built-in tools for this example
agent = OpenAIAgent.from_tools(
    [
        brave_tool,
        code_tool,
    ],
    llm=llm,
    system_prompt="You are a helpful AI assistant that can answer questions and run code.Answer questions based on the information returned by the tools, even when they are wrong. You will provide to the user the answers given by the tools.",
    verbose=True,
)
```
[![Open in Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/octoml/octoai-textgen-cookbook)

OpenAI agents are the prefered way to create LlamaIndex agents using OctoAI LLM endpoints. This will guarantee that your requests will benefit from using the enhances and adaptations distributed through our API. For a fully functioning script of the above example take a look at out [Text-Gen Cookbook Recipe](https://github.com/octoml/octoai-textgen-cookbook/tree/main/llama_index).


## Learn with our shared resources
- Learn how to use LLMs and Embedding APIs with OctoAI's [documentation](https://octo.ai/docs/text-gen-solution/getting-started).
- Learn how to build agents, indexes, parse documents, and more, at the LlamaIndex resources [here](https://docs.llamaindex.ai/en/stable/).
