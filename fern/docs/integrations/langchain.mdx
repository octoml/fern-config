---
title: LangChain Integration
subtitle:
  Langchain developers can leverage OctoAI LLM and embedding endpoints to easily
  access efficient compute across a wide selection of LLMs.
slug: integrations/langchain
---

## Introduction

LangChain provides a framework to easily build LLM-powered apps. Developers using LangChain can now utilize OctoAI LLMs and Embedding endpoints
to access efficient, fast, and reliable compute.

## Using OctoAI's LLMs and LangChain

To use OctoAI LLMs with LangChain, first install the following dependencies in your environment:
```bash
pip install langchain langchain-community openai
```

Secondly, [obtain an OctoAI API Token](/docs/getting-started/how-to-create-octoai-access-token).
Then paste your API token and run the code example below:

```python
# Set your api key via the OCTOAI_API_TOKEN environment variable
from langchain_community.chat_models.octoai import ChatOctoAI

llm = ChatOctoAI(
    model_name="meta-llama-3.1-70b-instruct",
    max_tokens=10000,
    temperature=0.4,
    model_kwargs={},
)

messages = [
    (
        "system",
        "You are a helpful assistant. Provide short answers to the user's questions.",
    ),
    ("human", "Who was Leonardo DaVinci?"),
]
ai_msg = llm.invoke(messages)

print(ai_msg.content)
```

It should produce the following output:

```
Leonardo da Vinci was a renowned Italian polymath, born in 1452. He was an artist, inventor, engineer, anatomist, and scientist. He is famous for his iconic paintings, such as the Mona Lisa and The Last Supper, as well as his inventions and designs that were centuries ahead of his time.
```

## Using OctoAI's Embeddings and LangChain
Using OctoAI's Embeddings endpoint is easy with LangChain.

We require the following dependencies:
```bash
pip install langchain langchain-community openai transformers
```

And now you can run the code example below:
```python
from langchain_community.embeddings.octoai_embeddings import OctoAIEmbeddings

embeddings = OctoAIEmbeddings()
text = "This is a test query."
query_result = embeddings.embed_query(text)
print(query_result)
```

### Learn with our demo apps

Get started today by following along with one of our demo apps:

- [DocTalk](https://octo.ai/demos/doctalk/)
- [Q&A app on a custom PDF](https://octo.ai/demos/q-a-on-custom-pdf/)
- [OctoAI Text Generation Cookbook](https://github.com/octoml/octoai-textgen-cookbook/)
